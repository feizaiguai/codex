#!/usr/bin/env python3
"""
36-deep-research å‘½ä»¤è¡Œæ¥å£

æ·±åº¦ç ”ç©¶å¼•æ“ï¼šä¸‰ AI åä½œæœç´¢ç³»ç»Ÿ
- Claude: æŠ€æœ¯æ·±åº¦åˆ†æã€æ¶æ„è®¾è®¡ã€å®‰å…¨æœ€ä½³å®è·µ
- Gemini: ç”Ÿæ€ç³»ç»Ÿåˆ†æã€è¶‹åŠ¿é¢„æµ‹ã€ç¤¾åŒºæ´å¯Ÿ
- Codex: ä»£ç å®è·µã€ç¤ºä¾‹é¡¹ç›®ã€å·¥å…·é“¾æ¨è

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python handler.py "React Server Components"
    python handler.py "Kubernetes security best practices"
    python handler.py --query "Python async programming" --max-tokens 15000
"""

import sys
import asyncio
import argparse
from pathlib import Path
from typing import Optional

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from deep_research import DeepResearchOrchestrator, estimate_tokens, split_report_by_tokens


def parse_arguments() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°

    Returns:
        è§£æåçš„å‚æ•°å‘½åç©ºé—´
    """
    parser = argparse.ArgumentParser(
        description="æ·±åº¦ç ”ç©¶å¼•æ“ - ä¸‰ AI åä½œæœç´¢ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  %(prog)s "React Server Components"
  %(prog)s --query "Kubernetes security" --max-tokens 15000
  %(prog)s -q "Python async" -o research_output.md

ä¸‰ AI åˆ†å·¥ï¼š
  Claude:  æŠ€æœ¯æ·±åº¦ã€æ¶æ„è®¾è®¡ã€å®‰å…¨å®è·µ
  Gemini:  ç”Ÿæ€ç³»ç»Ÿã€è¶‹åŠ¿åˆ†æã€ç¤¾åŒºæ´å¯Ÿ
  Codex:   ä»£ç å®è·µã€ç¤ºä¾‹é¡¹ç›®ã€å·¥å…·æ¨è
        """
    )

    parser.add_argument(
        'query',
        nargs='?',
        help='ç ”ç©¶ä¸»é¢˜ï¼ˆå¦‚æœä½¿ç”¨ -q/--query åˆ™æ­¤å‚æ•°å¯é€‰ï¼‰'
    )

    parser.add_argument(
        '-q', '--query',
        dest='query_flag',
        help='ç ”ç©¶ä¸»é¢˜ï¼ˆä¸ä½ç½®å‚æ•°äºŒé€‰ä¸€ï¼‰'
    )

    parser.add_argument(
        '-o', '--output',
        help='è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰'
    )

    parser.add_argument(
        '--max-tokens',
        type=int,
        default=20000,
        help='æ¯ä¸ªæ–‡ä»¶çš„æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ 20000ï¼‰'
    )

    parser.add_argument(
        '--no-split',
        action='store_true',
        help='ç¦ç”¨è‡ªåŠ¨åˆ†å‰²ï¼ˆå³ä½¿è¶…è¿‡ token é™åˆ¶ä¹Ÿä¿å­˜ä¸ºå•æ–‡ä»¶ï¼‰'
    )

    parser.add_argument(
        '--preview-lines',
        type=int,
        default=50,
        help='é¢„è§ˆçš„è¡Œæ•°ï¼ˆé»˜è®¤ 50ï¼‰'
    )

    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º'
    )

    parser.add_argument(
        '--version',
        action='version',
        version='%(prog)s 1.0.0'
    )

    return parser.parse_args()


def get_query_from_args(args: argparse.Namespace) -> str:
    """
    ä»å‚æ•°ä¸­è·å–æŸ¥è¯¢å­—ç¬¦ä¸²

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°

    Returns:
        æŸ¥è¯¢å­—ç¬¦ä¸²

    Raises:
        ValueError: å¦‚æœæ²¡æœ‰æä¾›æŸ¥è¯¢å­—ç¬¦ä¸²
    """
    query = args.query or args.query_flag

    if not query:
        raise ValueError(
            "é”™è¯¯ï¼šå¿…é¡»æä¾›ç ”ç©¶ä¸»é¢˜\n\n"
            "ä½¿ç”¨æ–¹å¼ï¼š\n"
            "  python handler.py \"ç ”ç©¶ä¸»é¢˜\"\n"
            "  python handler.py --query \"ç ”ç©¶ä¸»é¢˜\"\n\n"
            "ç¤ºä¾‹ï¼š\n"
            "  python handler.py \"React Server Components\"\n"
            "  python handler.py --query \"Kubernetes security best practices\""
        )

    return query


def generate_output_filename(query: str, output: Optional[str], part: Optional[int] = None) -> str:
    """
    ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å

    Args:
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        output: ç”¨æˆ·æŒ‡å®šçš„è¾“å‡ºæ–‡ä»¶å
        part: åˆ†æ®µç¼–å·ï¼ˆå¦‚æœåˆ†å‰²ï¼‰

    Returns:
        è¾“å‡ºæ–‡ä»¶å
    """
    if output:
        # ç”¨æˆ·æŒ‡å®šäº†æ–‡ä»¶å
        if part is not None:
            # æ·»åŠ åˆ†æ®µåç¼€
            base, ext = output.rsplit('.', 1) if '.' in output else (output, 'md')
            return f"{base}_part{part}.{ext}"
        return output
    else:
        # è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
        safe_query = query.replace(' ', '_')[:50]
        if part is not None:
            return f"research_{safe_query}_part{part}.md"
        return f"research_{safe_query}.md"


async def main() -> int:
    """
    ä¸»å‡½æ•°

    Returns:
        é€€å‡ºç ï¼ˆ0 è¡¨ç¤ºæˆåŠŸï¼‰
    """
    try:
        # è§£æå‚æ•°
        args = parse_arguments()

        # è·å–æŸ¥è¯¢å­—ç¬¦ä¸²
        query = get_query_from_args(args)

        # æ‰§è¡Œç ”ç©¶
        print(f"ğŸ” å¼€å§‹æ·±åº¦ç ”ç©¶: {query}")
        print("=" * 80)

        orchestrator = DeepResearchOrchestrator()
        report = await orchestrator.execute(query)

        # ä¼°ç®— token æ•°é‡
        estimated_tokens = estimate_tokens(report)

        if args.verbose:
            print(f"\nğŸ“Š æŠ¥å‘Šç»Ÿè®¡:")
            print(f"  - æ€»å­—ç¬¦æ•°: {len(report):,}")
            print(f"  - ä¼°ç®— tokens: {estimated_tokens:,}")
            print(f"  - Token é™åˆ¶: {args.max_tokens:,}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å‰²
        if not args.no_split and estimated_tokens > args.max_tokens:
            print(f"\nâš ï¸  æŠ¥å‘Šè¶…è¿‡ {args.max_tokens:,} tokens é™åˆ¶ï¼Œè‡ªåŠ¨åˆ†å‰²ä¸ºå¤šä¸ªæ–‡ä»¶...")

            report_parts = split_report_by_tokens(report, max_tokens=args.max_tokens)

            # ä¿å­˜å¤šä¸ªæ–‡ä»¶
            saved_files = []

            for i, part in enumerate(report_parts, 1):
                output_file = generate_output_filename(query, args.output, part=i)

                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(part)

                part_tokens = estimate_tokens(part)
                print(f"   âœ… Part {i}/{len(report_parts)}: {output_file} ({part_tokens:,} tokens)")
                saved_files.append(output_file)

            print(f"\nğŸ“„ æŠ¥å‘Šå·²åˆ†å‰²ä¿å­˜ä¸º {len(report_parts)} ä¸ªæ–‡ä»¶:")
            for f in saved_files:
                print(f"   - {f}")
        else:
            # å•æ–‡ä»¶ä¿å­˜
            output_file = generate_output_filename(query, args.output)

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report)

            print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            print(f"   - æ€»å­—ç¬¦æ•°: {len(report):,}")
            print(f"   - ä¼°ç®— tokens: {estimated_tokens:,}")

        # æ˜¾ç¤ºé¢„è§ˆ
        print("\n" + "=" * 80)
        print(f"æŠ¥å‘Šé¢„è§ˆï¼ˆå‰ {args.preview_lines} è¡Œï¼‰:")
        print("=" * 80)
        preview_lines = report.split('\n')[:args.preview_lines]
        print('\n'.join(preview_lines))

        if len(report.split('\n')) > args.preview_lines:
            print(f"\n... (å®Œæ•´æŠ¥å‘Šå…± {len(report.split('\n'))} è¡Œï¼Œè¯·æŸ¥çœ‹æ–‡ä»¶)")

        print("\nâœ… ç ”ç©¶å®Œæˆï¼")
        return 0

    except ValueError as e:
        print(str(e), file=sys.stderr)
        return 1
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ", file=sys.stderr)
        return 130
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
