#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WeChat Trending Analyzer - å¾®ä¿¡çƒ­æœåˆ†æå™¨

Author: Claude Code Skills Team
Version: 1.0.0
License: MIT
"""

import os
import requests
import json
from datetime import datetime
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
import urllib3
import subprocess
import os
from urllib.parse import quote

# ç¦ç”¨SSLè­¦å‘Šï¼ˆè§£å†³Windows SSLéªŒè¯é—®é¢˜ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


@dataclass
class TrendingTopic:
    """å¾®ä¿¡çƒ­æœè¯é¢˜æ•°æ®æ¨¡å‹"""
    rank: int
    title: str
    url: str = ""
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class WeChatTrendingConfig:
    """é…ç½®å‚æ•°"""
    api_key: str = ""
    api_url: str = "https://apis.tianapi.com/wxhottopic/index"
    limit: int = 10
    keyword: Optional[str] = None
    include_analysis: bool = True
    timeout: int = 10
    max_retries: int = 3


class WeChatTrendingAnalyzer:
    """å¾®ä¿¡çƒ­æœåˆ†æå™¨æ ¸å¿ƒç±»"""

    def __init__(self, config: WeChatTrendingConfig = None):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.config = config or WeChatTrendingConfig()
        self.update_time = None
        self.topics: List[TrendingTopic] = []

    def fetch_trending(self) -> List[Dict]:
        """
        ä»å¤©è¡ŒAPIè·å–å¾®ä¿¡çƒ­æœæ¦œå•

        Returns:
            List[Dict]: çƒ­æœæ¦œå•åŸå§‹æ•°æ®

        Raises:
            Exception: APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        api_key = os.environ.get("TIANAPI_KEY") or self.config.api_key
        if not api_key:
            raise ValueError("ç¼ºå°‘ TIANAPI_KEY")
        params = {"key": api_key}

        for attempt in range(self.config.max_retries):
            try:
                print(f"ğŸ“¡ æ­£åœ¨è·å–å¾®ä¿¡çƒ­æœ... (å°è¯• {attempt + 1}/{self.config.max_retries})")

                # æ·»åŠ è¯·æ±‚å¤´å’Œç¦ç”¨SSLéªŒè¯
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'application/json, text/plain, */*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                }

                response = requests.get(
                    self.config.api_url,
                    params=params,
                    headers=headers,
                    timeout=self.config.timeout,
                    verify=False  # ç¦ç”¨SSLéªŒè¯è§£å†³Windows SSLé—®é¢˜
                )
                response.raise_for_status()
                data = response.json()

                # æ£€æŸ¥APIå“åº”çŠ¶æ€
                if data.get('code') == 200:
                    result = data.get('result', {})
                    trending_list = result.get('list', [])
                    self.update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                    print(f"âœ… æˆåŠŸè·å– {len(trending_list)} æ¡çƒ­æœ")
                    return trending_list

                else:
                    error_msg = data.get('msg', 'Unknown error')
                    raise Exception(f"APIé”™è¯¯: {error_msg}")

            except requests.Timeout:
                print(f"âš ï¸ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1})")
                if attempt == self.config.max_retries - 1:
                    raise Exception("è·å–çƒ­æœå¤±è´¥: è¯·æ±‚è¶…æ—¶")

            except requests.RequestException as e:
                print(f"âš ï¸ ç½‘ç»œé”™è¯¯: {str(e)}")
                if attempt == self.config.max_retries - 1:
                    raise Exception(f"è·å–çƒ­æœå¤±è´¥: {str(e)}")

            except Exception as e:
                raise Exception(f"è·å–çƒ­æœå¤±è´¥: {str(e)}")

        raise Exception("è·å–çƒ­æœå¤±è´¥: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")

    def parse_topics(self, raw_data: List[Dict]) -> List[TrendingTopic]:
        """
        è§£æåŸå§‹çƒ­æœæ•°æ®

        Args:
            raw_data: APIè¿”å›çš„åŸå§‹æ•°æ®

        Returns:
            List[TrendingTopic]: è§£æåçš„çƒ­æœè¯é¢˜åˆ—è¡¨
        """
        topics = []

        for item in raw_data:
            # å¾®ä¿¡çƒ­æœAPIè¿”å›çš„æ•°æ®æ ¼å¼ï¼šwordå’Œindex
            title = item.get('word', '')
            index = item.get('index', 0)

            if not title:
                continue

            # ç”Ÿæˆå¾®ä¿¡æœç´¢URLï¼ˆç¼–ç ä¸­æ–‡ï¼‰
            encoded_title = quote(title)
            url = f"https://weixin.sogou.com/weixin?type=2&query={encoded_title}"

            topic = TrendingTopic(
                rank=index + 1,  # indexä»0å¼€å§‹ï¼Œrankä»1å¼€å§‹
                title=title,
                url=url
            )
            topics.append(topic)

        print(f"ğŸ“‹ è§£æå®Œæˆ: {len(topics)} æ¡çƒ­æœ")
        return topics

    def filter_topics(self, topics: List[TrendingTopic]) -> List[TrendingTopic]:
        """
        æ ¹æ®é…ç½®ç­›é€‰è¯é¢˜

        Args:
            topics: æ‰€æœ‰è¯é¢˜åˆ—è¡¨

        Returns:
            List[TrendingTopic]: ç­›é€‰åçš„è¯é¢˜åˆ—è¡¨
        """
        filtered = topics

        # å…³é”®è¯ç­›é€‰
        if self.config.keyword:
            keyword = self.config.keyword.lower()
            filtered = [
                t for t in filtered
                if keyword in t.title.lower()
            ]
            print(f"ğŸ” å…³é”®è¯ç­›é€‰ '{self.config.keyword}': {len(filtered)} æ¡ç»“æœ")

        # æ•°é‡é™åˆ¶
        filtered = filtered[:self.config.limit]
        print(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered)} æ¡è¯é¢˜")

        return filtered

    def search_topic_details(self, topic: TrendingTopic) -> Dict[str, Any]:
        """
        ä½¿ç”¨15-web-search-Gæœç´¢è¯é¢˜è¯¦ç»†ä¿¡æ¯

        Args:
            topic: çƒ­æœè¯é¢˜

        Returns:
            Dict: è¯é¢˜è¯¦ç»†ä¿¡æ¯
        """
        try:
            # 15-web-search-G skillçš„è·¯å¾„
            web_search_path = "C:/Users/bigbao/.codex/skills/15-web-search-G"
            cli_path = os.path.join(web_search_path, "cli.py")

            if not os.path.exists(cli_path):
                return {
                    "summary": f"å…³äº \"{topic.title}\" çš„æœç´¢æš‚æ—¶å¤±è´¥",
                    "background": "15-web-search-G skillæœªå®‰è£…",
                    "key_points": [],
                    "sources": []
                }

            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_query = f"{topic.title} æœ€æ–°æ¶ˆæ¯ èƒŒæ™¯ æ–°é—»"

            # è°ƒç”¨15-web-search-G
            cmd = [
                "python", cli_path,
                search_query,
                "--mode", "auto",
                "--max-results", "10",
                "--time-range", "week",
                "--language", "zh",
                "--output", "markdown"
            ]

            result = subprocess.run(
                cmd,
                cwd=web_search_path,
                capture_output=True,
                text=True,
                timeout=30,
                encoding='utf-8',
                errors='ignore'
            )

            if result.returncode == 0 and result.stdout:
                # è§£ææœç´¢ç»“æœï¼ˆç®€å•æå–å…³é”®ä¿¡æ¯ï¼‰
                output = result.stdout

                # æå–æ‘˜è¦ï¼ˆå–ç¬¬ä¸€æ®µéç©ºå†…å®¹ï¼‰
                lines = [line.strip() for line in output.split('\n') if line.strip()]
                summary = lines[0] if lines else f"{topic.title}"

                return {
                    "summary": summary[:200] if len(summary) > 200 else summary,
                    "background": "è¯¦è§æœç´¢ç»“æœ",
                    "key_points": lines[1:4] if len(lines) > 1 else [],
                    "sources": ["15-web-search-G"]
                }
            else:
                return {
                    "summary": f"å…³äº \"{topic.title}\" çš„æœç´¢æš‚æ—¶å¤±è´¥",
                    "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                    "key_points": [],
                    "sources": []
                }

        except subprocess.TimeoutExpired:
            return {
                "summary": f"å…³äº \"{topic.title}\" çš„æœç´¢è¶…æ—¶",
                "background": "æœç´¢æœåŠ¡è¶…æ—¶",
                "key_points": [],
                "sources": []
            }
        except Exception as e:
            return {
                "summary": f"å…³äº \"{topic.title}\" çš„æœç´¢æš‚æ—¶å¤±è´¥",
                "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                "key_points": [],
                "sources": []
            }

    def enrich_topics(self, topics: List[TrendingTopic]) -> None:
        """
        ä¸ºæ¯ä¸ªè¯é¢˜æœç´¢è¯¦ç»†ä¿¡æ¯

        Args:
            topics: è¯é¢˜åˆ—è¡¨ï¼ˆä¼šç›´æ¥ä¿®æ”¹ï¼‰
        """
        if not self.config.include_analysis:
            return

        print(f"\nğŸ” æ­£åœ¨æœç´¢è¯é¢˜è¯¦ç»†ä¿¡æ¯...")

        for i, topic in enumerate(topics, 1):
            print(f"[{i}/{len(topics)}]   ğŸ” æ­£åœ¨æœç´¢: {topic.title}")

            try:
                details = self.search_topic_details(topic)
                topic.details = details
                print(f"  âœ… æœç´¢å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸ æœç´¢å¤±è´¥: {str(e)[:100]}")
                topic.details = {
                    "summary": f"å…³äº \"{topic.title}\" çš„æœç´¢æš‚æ—¶å¤±è´¥",
                    "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                    "key_points": [],
                    "sources": []
                }

    def generate_report(self, topics: List[TrendingTopic]) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„çƒ­æœæŠ¥å‘Š

        Args:
            topics: è¯é¢˜åˆ—è¡¨

        Returns:
            str: Markdownæ ¼å¼æŠ¥å‘Š
        """
        report_lines = []

        # æ ‡é¢˜
        report_lines.append("# ğŸ’¬ å¾®ä¿¡çƒ­æœæ¦œ")
        report_lines.append("")
        report_lines.append(f"**æ›´æ–°æ—¶é—´**: {self.update_time}")
        report_lines.append(f"**çƒ­æœæ•°é‡**: {len(topics)} æ¡")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # çƒ­æœè¯é¢˜
        report_lines.append(f"## ğŸ”¥ Top {len(topics)} çƒ­æœè¯é¢˜")
        report_lines.append("")

        for topic in topics:
            # è¯é¢˜æ ‡é¢˜
            report_lines.append(f"### {topic.rank}. {topic.title}")
            report_lines.append("")

            # å¦‚æœæœ‰è¯¦ç»†ä¿¡æ¯
            if topic.details and self.config.include_analysis:
                summary = topic.details.get('summary', '')
                background = topic.details.get('background', '')

                if summary:
                    report_lines.append(f"**è¯é¢˜æ¦‚è¿°**: {summary}")
                    report_lines.append("")

                if background and background != "è¯¦è§æœç´¢ç»“æœ":
                    report_lines.append(f"**èƒŒæ™¯ä¿¡æ¯**: {background}")
                    report_lines.append("")

                key_points = topic.details.get('key_points', [])
                if key_points:
                    report_lines.append("**å…³é”®è¦ç‚¹**:")
                    for point in key_points[:3]:
                        report_lines.append(f"- {point}")
                    report_lines.append("")

            # å¾®ä¿¡æœç´¢é“¾æ¥
            report_lines.append(f"**ğŸ”— å¾®ä¿¡æœç´¢**: [{topic.title}]({topic.url})")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # æ•°æ®è¯´æ˜
        report_lines.append("## ğŸ“Š æ•°æ®è¯´æ˜")
        report_lines.append("")
        report_lines.append("- **æ•°æ®æº**: å¤©è¡ŒAPI (å¾®ä¿¡çƒ­æœ)")
        report_lines.append("- **æ›´æ–°é¢‘ç‡**: å®æ—¶æ›´æ–°")
        report_lines.append(f"- **æ•°æ®æ—¶æ•ˆ**: {self.update_time}")
        report_lines.append("")

        return "\n".join(report_lines)

    def save_report(self, report: str, filename: str = None) -> str:
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report: æŠ¥å‘Šå†…å®¹
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"wechat_trending_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)

        return filename

    def analyze(self) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹

        Returns:
            str: Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        try:
            print("ğŸš€ å¼€å§‹å¾®ä¿¡çƒ­æœåˆ†æ...\n")

            # 1. è·å–çƒ­æœæ•°æ®
            raw_data = self.fetch_trending()

            # 2. è§£ææ•°æ®
            self.topics = self.parse_topics(raw_data)

            # 3. ç­›é€‰è¯é¢˜
            filtered_topics = self.filter_topics(self.topics)

            # 4. æœç´¢è¯¦ç»†ä¿¡æ¯
            self.enrich_topics(filtered_topics)

            # 5. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(filtered_topics)

            print("\nâœ… åˆ†æå®Œæˆ!\n")
            return report

        except Exception as e:
            error_report = f"# âŒ é”™è¯¯\n\nâŒ åˆ†æå¤±è´¥: {str(e)}\n"
            print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}\n")
            return error_report


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='å¾®ä¿¡çƒ­æœåˆ†æå™¨')
    parser.add_argument('--limit', type=int, default=10, help='è¿”å›çƒ­æœæ•°é‡ (é»˜è®¤: 10)')
    parser.add_argument('--keyword', type=str, help='å…³é”®è¯ç­›é€‰')
    parser.add_argument('--no-analysis', action='store_true', help='ä¸åŒ…å«è¯¦ç»†åˆ†æ')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åˆ›å»ºé…ç½®
    config = WeChatTrendingConfig(
        limit=args.limit,
        keyword=args.keyword,
        include_analysis=not args.no_analysis
    )

    # æ‰§è¡Œåˆ†æ
    analyzer = WeChatTrendingAnalyzer(config)
    report = analyzer.analyze()

    # è¾“å‡ºæŠ¥å‘Š
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    output_file = analyzer.save_report(report, args.output)
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")


if __name__ == "__main__":
    main()
