#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI News Analyzer - AIèµ„è®¯åˆ†æå™¨

Author: Claude Code Skills Team
Version: 1.0.0
License: MIT
"""

import os
import requests
import json
from datetime import datetime
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
import urllib3
import subprocess
import os
from urllib.parse import quote

# ç¦ç”¨SSLè­¦å‘Šï¼ˆè§£å†³Windows SSLéªŒè¯é—®é¢˜ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


@dataclass
class AINewsItem:
    """AIèµ„è®¯æ•°æ®æ¨¡å‹"""
    rank: int
    title: str
    description: str
    source: str
    url: str
    publish_time: str
    pic_url: str = ""
    news_id: str = ""
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AINewsConfig:
    """é…ç½®å‚æ•°"""
    api_key: str = ""
    api_url: str = "https://apis.tianapi.com/ai/index"
    limit: int = 10
    keyword: Optional[str] = None
    include_analysis: bool = True
    timeout: int = 10
    max_retries: int = 3


class AINewsAnalyzer:
    """AIèµ„è®¯åˆ†æå™¨æ ¸å¿ƒç±»"""

    def __init__(self, config: AINewsConfig = None):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.config = config or AINewsConfig()
        self.update_time = None
        self.news_items: List[AINewsItem] = []

    def fetch_news(self) -> List[Dict]:
        """
        ä»å¤©è¡ŒAPIè·å–AIèµ„è®¯

        Returns:
            List[Dict]: AIèµ„è®¯åŸå§‹æ•°æ®

        Raises:
            Exception: APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        api_key = os.environ.get("TIANAPI_KEY") or self.config.api_key
        if not api_key:
            raise ValueError("ç¼ºå°‘ TIANAPI_KEY")
        params = {"key": api_key}

        for attempt in range(self.config.max_retries):
            try:
                print(f"ğŸ“¡ æ­£åœ¨è·å–AIèµ„è®¯... (å°è¯• {attempt + 1}/{self.config.max_retries})")

                # æ·»åŠ è¯·æ±‚å¤´å’Œç¦ç”¨SSLéªŒè¯
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'application/json, text/plain, */*',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                }

                response = requests.get(
                    self.config.api_url,
                    params=params,
                    headers=headers,
                    timeout=self.config.timeout,
                    verify=False  # ç¦ç”¨SSLéªŒè¯è§£å†³Windows SSLé—®é¢˜
                )
                response.raise_for_status()
                data = response.json()

                # æ£€æŸ¥APIå“åº”çŠ¶æ€
                if data.get('code') == 200:
                    result = data.get('result', {})
                    news_list = result.get('newslist', [])
                    self.update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                    print(f"âœ… æˆåŠŸè·å– {len(news_list)} æ¡AIèµ„è®¯")
                    return news_list

                else:
                    error_msg = data.get('msg', 'Unknown error')
                    raise Exception(f"APIé”™è¯¯: {error_msg}")

            except requests.Timeout:
                print(f"âš ï¸ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1})")
                if attempt == self.config.max_retries - 1:
                    raise Exception("è·å–AIèµ„è®¯å¤±è´¥: è¯·æ±‚è¶…æ—¶")

            except requests.RequestException as e:
                print(f"âš ï¸ ç½‘ç»œé”™è¯¯: {str(e)}")
                if attempt == self.config.max_retries - 1:
                    raise Exception(f"è·å–AIèµ„è®¯å¤±è´¥: {str(e)}")

            except Exception as e:
                raise Exception(f"è·å–AIèµ„è®¯å¤±è´¥: {str(e)}")

        raise Exception("è·å–AIèµ„è®¯å¤±è´¥: è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")

    def parse_news(self, raw_data: List[Dict]) -> List[AINewsItem]:
        """
        è§£æåŸå§‹AIèµ„è®¯æ•°æ®

        Args:
            raw_data: APIè¿”å›çš„åŸå§‹æ•°æ®

        Returns:
            List[AINewsItem]: è§£æåçš„AIèµ„è®¯åˆ—è¡¨
        """
        news_items = []

        for index, item in enumerate(raw_data, start=1):
            # AIèµ„è®¯APIè¿”å›çš„æ•°æ®æ ¼å¼
            title = item.get('title', '')
            description = item.get('description', '')
            source = item.get('source', '')
            url = item.get('url', '')
            ctime = item.get('ctime', '')
            pic_url = item.get('picUrl', '')
            news_id = item.get('id', '')

            if not title:
                continue

            news_item = AINewsItem(
                rank=index,
                title=title,
                description=description,
                source=source,
                url=url,
                publish_time=ctime,
                pic_url=pic_url,
                news_id=news_id
            )
            news_items.append(news_item)

        print(f"ğŸ“‹ è§£æå®Œæˆ: {len(news_items)} æ¡AIèµ„è®¯")
        return news_items

    def filter_news(self, news_items: List[AINewsItem]) -> List[AINewsItem]:
        """
        æ ¹æ®é…ç½®ç­›é€‰èµ„è®¯

        Args:
            news_items: æ‰€æœ‰èµ„è®¯åˆ—è¡¨

        Returns:
            List[AINewsItem]: ç­›é€‰åçš„èµ„è®¯åˆ—è¡¨
        """
        filtered = news_items

        # å…³é”®è¯ç­›é€‰
        if self.config.keyword:
            keyword = self.config.keyword.lower()
            filtered = [
                item for item in filtered
                if keyword in item.title.lower() or keyword in item.description.lower()
            ]
            print(f"ğŸ” å…³é”®è¯ç­›é€‰ '{self.config.keyword}': {len(filtered)} æ¡ç»“æœ")

        # æ•°é‡é™åˆ¶
        filtered = filtered[:self.config.limit]
        print(f"âœ… ç­›é€‰å®Œæˆ: {len(filtered)} æ¡èµ„è®¯")

        return filtered

    def search_news_details(self, news_item: AINewsItem) -> Dict[str, Any]:
        """
        ä½¿ç”¨15-web-search-Gæœç´¢èµ„è®¯è¯¦ç»†ä¿¡æ¯

        Args:
            news_item: AIèµ„è®¯æ¡ç›®

        Returns:
            Dict: èµ„è®¯è¯¦ç»†ä¿¡æ¯
        """
        try:
            # 15-web-search-G skillçš„è·¯å¾„
            web_search_path = "C:/Users/bigbao/.codex/skills/15-web-search-G"
            cli_path = os.path.join(web_search_path, "cli.py")

            if not os.path.exists(cli_path):
                return {
                    "summary": f"å…³äº \"{news_item.title}\" çš„æœç´¢æš‚æ—¶å¤±è´¥",
                    "background": "15-web-search-G skillæœªå®‰è£…",
                    "key_points": [],
                    "sources": []
                }

            # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆä½¿ç”¨æ ‡é¢˜ + å…³é”®è¯ï¼‰
            search_query = f"{news_item.title} è¯¦ç»† åˆ†æ"

            # è°ƒç”¨15-web-search-G
            cmd = [
                "python", cli_path,
                search_query,
                "--mode", "auto",
                "--max-results", "10",
                "--time-range", "week",
                "--language", "zh",
                "--output", "markdown"
            ]

            result = subprocess.run(
                cmd,
                cwd=web_search_path,
                capture_output=True,
                text=True,
                timeout=30,
                encoding='utf-8',
                errors='ignore'
            )

            if result.returncode == 0 and result.stdout:
                # è§£ææœç´¢ç»“æœï¼ˆç®€å•æå–å…³é”®ä¿¡æ¯ï¼‰
                output = result.stdout

                # æå–æ‘˜è¦ï¼ˆå–ç¬¬ä¸€æ®µéç©ºå†…å®¹ï¼‰
                lines = [line.strip() for line in output.split('\n') if line.strip()]
                summary = lines[0] if lines else news_item.description

                return {
                    "summary": summary[:200] if len(summary) > 200 else summary,
                    "background": "è¯¦è§æœç´¢ç»“æœ",
                    "key_points": lines[1:4] if len(lines) > 1 else [],
                    "sources": ["15-web-search-G"]
                }
            else:
                return {
                    "summary": news_item.description,
                    "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                    "key_points": [],
                    "sources": []
                }

        except subprocess.TimeoutExpired:
            return {
                "summary": news_item.description,
                "background": "æœç´¢æœåŠ¡è¶…æ—¶",
                "key_points": [],
                "sources": []
            }
        except Exception as e:
            return {
                "summary": news_item.description,
                "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                "key_points": [],
                "sources": []
            }

    def enrich_news(self, news_items: List[AINewsItem]) -> None:
        """
        ä¸ºæ¯æ¡èµ„è®¯æœç´¢è¯¦ç»†ä¿¡æ¯

        Args:
            news_items: èµ„è®¯åˆ—è¡¨ï¼ˆä¼šç›´æ¥ä¿®æ”¹ï¼‰
        """
        if not self.config.include_analysis:
            return

        print(f"\nğŸ” æ­£åœ¨æœç´¢èµ„è®¯è¯¦ç»†ä¿¡æ¯...")

        for i, news_item in enumerate(news_items, 1):
            print(f"[{i}/{len(news_items)}] ğŸ” æ­£åœ¨æœç´¢: {news_item.title}")

            try:
                details = self.search_news_details(news_item)
                news_item.details = details
                print(f"  âœ… æœç´¢å®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸ æœç´¢å¤±è´¥: {str(e)[:100]}")
                news_item.details = {
                    "summary": news_item.description,
                    "background": "æœç´¢æœåŠ¡æš‚ä¸å¯ç”¨",
                    "key_points": [],
                    "sources": []
                }

    def generate_report(self, news_items: List[AINewsItem]) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„AIèµ„è®¯æŠ¥å‘Š

        Args:
            news_items: èµ„è®¯åˆ—è¡¨

        Returns:
            str: Markdownæ ¼å¼æŠ¥å‘Š
        """
        report_lines = []

        # æ ‡é¢˜
        report_lines.append("# ğŸ¤– AIèµ„è®¯é€Ÿé€’")
        report_lines.append("")
        report_lines.append(f"**æ›´æ–°æ—¶é—´**: {self.update_time}")
        report_lines.append(f"**èµ„è®¯æ•°é‡**: {len(news_items)} æ¡")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # AIèµ„è®¯æ¡ç›®
        report_lines.append(f"## ğŸ“° Top {len(news_items)} AIèµ„è®¯")
        report_lines.append("")

        for news_item in news_items:
            # èµ„è®¯æ ‡é¢˜
            report_lines.append(f"### {news_item.rank}. {news_item.title}")
            report_lines.append("")

            # åŸºæœ¬ä¿¡æ¯
            report_lines.append(f"**ğŸ“… å‘å¸ƒæ—¶é—´**: {news_item.publish_time}")
            report_lines.append(f"**ğŸ“Œ æ¥æº**: {news_item.source}")
            report_lines.append("")

            # èµ„è®¯æè¿°
            if news_item.description:
                report_lines.append(f"**ğŸ“ å†…å®¹æ¦‚è¿°**: {news_item.description}")
                report_lines.append("")

            # å¦‚æœæœ‰è¯¦ç»†ä¿¡æ¯
            if news_item.details and self.config.include_analysis:
                summary = news_item.details.get('summary', '')
                background = news_item.details.get('background', '')

                if summary and summary != news_item.description:
                    report_lines.append(f"**ğŸ’¡ æ·±åº¦è§£è¯»**: {summary}")
                    report_lines.append("")

                key_points = news_item.details.get('key_points', [])
                if key_points:
                    report_lines.append("**ğŸ”‘ å…³é”®è¦ç‚¹**:")
                    for point in key_points[:3]:
                        report_lines.append(f"- {point}")
                    report_lines.append("")

            # åŸæ–‡é“¾æ¥
            report_lines.append(f"**ğŸ”— åŸæ–‡é“¾æ¥**: [{news_item.title}]({news_item.url})")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # æ•°æ®è¯´æ˜
        report_lines.append("## ğŸ“Š æ•°æ®è¯´æ˜")
        report_lines.append("")
        report_lines.append("- **æ•°æ®æº**: å¤©è¡ŒAPI (AIèµ„è®¯)")
        report_lines.append("- **æ›´æ–°é¢‘ç‡**: å®æ—¶æ›´æ–°")
        report_lines.append(f"- **æ•°æ®æ—¶æ•ˆ**: {self.update_time}")
        report_lines.append("")

        return "\n".join(report_lines)

    def save_report(self, report: str, filename: str = None) -> str:
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report: æŠ¥å‘Šå†…å®¹
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"ai_news_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)

        return filename

    def analyze(self) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹

        Returns:
            str: Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        try:
            print("ğŸš€ å¼€å§‹AIèµ„è®¯åˆ†æ...\n")

            # 1. è·å–AIèµ„è®¯æ•°æ®
            raw_data = self.fetch_news()

            # 2. è§£ææ•°æ®
            self.news_items = self.parse_news(raw_data)

            # 3. ç­›é€‰èµ„è®¯
            filtered_news = self.filter_news(self.news_items)

            # 4. æœç´¢è¯¦ç»†ä¿¡æ¯
            self.enrich_news(filtered_news)

            # 5. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(filtered_news)

            print("\nâœ… åˆ†æå®Œæˆ!\n")
            return report

        except Exception as e:
            error_report = f"# âŒ é”™è¯¯\n\nâŒ åˆ†æå¤±è´¥: {str(e)}\n"
            print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}\n")
            return error_report


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description='AIèµ„è®¯åˆ†æå™¨')
    parser.add_argument('--limit', type=int, default=10, help='è¿”å›èµ„è®¯æ•°é‡ (é»˜è®¤: 10)')
    parser.add_argument('--keyword', type=str, help='å…³é”®è¯ç­›é€‰')
    parser.add_argument('--no-analysis', action='store_true', help='ä¸åŒ…å«è¯¦ç»†åˆ†æ')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åˆ›å»ºé…ç½®
    config = AINewsConfig(
        limit=args.limit,
        keyword=args.keyword,
        include_analysis=not args.no_analysis
    )

    # æ‰§è¡Œåˆ†æ
    analyzer = AINewsAnalyzer(config)
    report = analyzer.analyze()

    # è¾“å‡ºæŠ¥å‘Š
    print(report)

    # ä¿å­˜æŠ¥å‘Š
    output_file = analyzer.save_report(report, args.output)
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")


if __name__ == "__main__":
    main()
