#!/usr/bin/env python3
"""
Chrome æµè§ˆå™¨è‡ªåŠ¨åŒ–å¼•æ“
åŸºäº Playwright æ§åˆ¶ Google Chrome æµè§ˆå™¨
"""

import os
import json
import time
from typing import Optional, List, Dict, Any, Union
from pathlib import Path
from playwright.sync_api import sync_playwright, Page, Browser, BrowserContext


class ChromeAutomation:
    """Chrome æµè§ˆå™¨è‡ªåŠ¨åŒ–æ ¸å¿ƒç±»"""

    def __init__(
        self,
        headless: bool = False,
        chrome_path: Optional[str] = None,
        window_size: tuple = (1920, 1080),
        user_agent: Optional[str] = None,
        proxy: Optional[Dict[str, str]] = None,
        timeout: int = 30000
    ):
        """
        åˆå§‹åŒ– Chrome æµè§ˆå™¨è‡ªåŠ¨åŒ–å¼•æ“

        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼ï¼ˆFalse æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼‰
            chrome_path: Chrome æµè§ˆå™¨è·¯å¾„ï¼ˆNone åˆ™è‡ªåŠ¨æ£€æµ‹ï¼‰
            window_size: çª—å£å¤§å° (width, height)
            user_agent: è‡ªå®šä¹‰ç”¨æˆ·ä»£ç†
            proxy: ä»£ç†é…ç½®
            timeout: é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        self.headless = headless
        self.chrome_path = chrome_path
        self.window_size = window_size
        self.user_agent = user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
        self.proxy = proxy
        self.timeout = timeout

        # Playwright å¯¹è±¡
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None

        # è‡ªåŠ¨å¯åŠ¨æµè§ˆå™¨
        self._launch_browser()

    def _launch_browser(self):
        """å¯åŠ¨ Chrome æµè§ˆå™¨"""
        self.playwright = sync_playwright().start()

        # å¯åŠ¨å‚æ•°
        launch_args = {
            "headless": self.headless,
            "channel": "chrome",  # ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ Chrome
            "args": [
                f"--window-size={self.window_size[0]},{self.window_size[1]}",
                "--disable-blink-features=AutomationControlled",
                "--no-sandbox",
                "--disable-setuid-sandbox",
            ]
        }

        # å¯åŠ¨æµè§ˆå™¨
        self.browser = self.playwright.chromium.launch(**launch_args)

        # åˆ›å»ºä¸Šä¸‹æ–‡
        context_args = {
            "viewport": {"width": self.window_size[0], "height": self.window_size[1]},
            "user_agent": self.user_agent,
            "accept_downloads": True
        }

        if self.proxy:
            context_args["proxy"] = self.proxy

        self.context = self.browser.new_context(**context_args)

        # åˆ›å»ºé¡µé¢
        self.page = self.context.new_page()
        self.page.set_default_timeout(self.timeout)

    def navigate(self, url: str, wait_until: str = "load"):
        """
        è®¿é—®ç½‘é¡µ

        Args:
            url: ç›®æ ‡ç½‘å€
            wait_until: ç­‰å¾…æ¡ä»¶ (load, domcontentloaded, networkidle)
        """
        print(f"ğŸŒ å¯¼èˆªåˆ°: {url}")
        self.page.goto(url, wait_until=wait_until)

    def reload(self):
        """åˆ·æ–°å½“å‰é¡µé¢"""
        self.page.reload()

    def wait_for_login(self, seconds: int = 60):
        """
        ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•

        Args:
            seconds: ç­‰å¾…ç§’æ•°
        """
        print("\n" + "=" * 70)
        print("æµè§ˆå™¨å·²æ‰“å¼€ï¼è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•ã€‚")
        print("=" * 70)
        print(f"ç¨‹åºå°†ç­‰å¾… {seconds} ç§’...\n")

        for i in range(seconds, 0, -10):
            print(f"â±ï¸  å‰©ä½™ {i} ç§’...")
            time.sleep(10)

        print("\nâœ“ ç­‰å¾…ç»“æŸï¼Œç»§ç»­æ‰§è¡Œè‡ªåŠ¨åŒ–æµç¨‹...")

    def wait_for_selector(self, selector: str, timeout: int = None):
        """ç­‰å¾…å…ƒç´ å‡ºç°"""
        timeout = timeout or self.timeout
        self.page.wait_for_selector(selector, timeout=timeout)

    def click(self, selector: str):
        """ç‚¹å‡»å…ƒç´ """
        self.page.click(selector)

    def type(self, selector: str, text: str, clear: bool = True):
        """è¾“å…¥æ–‡æœ¬"""
        if clear:
            self.page.fill(selector, text)
        else:
            self.page.type(selector, text)

    def select(self, selector: str, value: str):
        """é€‰æ‹©ä¸‹æ‹‰æ¡†"""
        self.page.select_option(selector, value)

    def get_text(self, selector: str) -> str:
        """è·å–å•ä¸ªå…ƒç´ æ–‡æœ¬"""
        elem = self.page.query_selector(selector)
        if elem:
            return elem.inner_text()
        return ""

    def get_all_text(self, selector: str) -> List[str]:
        """è·å–å¤šä¸ªå…ƒç´ æ–‡æœ¬"""
        texts = []
        elems = self.page.query_selector_all(selector)
        for elem in elems:
            try:
                texts.append(elem.inner_text())
            except:
                pass
        return texts

    def get_attr(self, selector: str, attr: str) -> str:
        """è·å–å…ƒç´ å±æ€§"""
        elem = self.page.query_selector(selector)
        if elem:
            return elem.get_attribute(attr) or ""
        return ""

    def is_visible(self, selector: str) -> bool:
        """æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§"""
        elem = self.page.query_selector(selector)
        if elem:
            return elem.is_visible()
        return False

    def extract_products(self, selector: str, fields: Dict[str, str]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æå–å•†å“æ•°æ®

        Args:
            selector: å•†å“å®¹å™¨é€‰æ‹©å™¨
            fields: å­—æ®µæ˜ å°„ {"å­—æ®µå": "é€‰æ‹©å™¨"}

        Returns:
            å•†å“åˆ—è¡¨
        """
        products = []
        elems = self.page.query_selector_all(selector)

        for elem in elems[:50]:  # æœ€å¤š 50 ä¸ª
            product = {}
            for field_name, field_selector in fields.items():
                try:
                    field_elem = elem.query_selector(field_selector)
                    if field_elem:
                        product[field_name] = field_elem.inner_text()
                except:
                    product[field_name] = ""
            products.append(product)

        return products

    def scrape_all_elements(self, selector: str, max_items: int = 20) -> List[Dict[str, Any]]:
        """
        æŠ“å–æ‰€æœ‰åŒ¹é…çš„å…ƒç´ 

        Args:
            selector: å…ƒç´ é€‰æ‹©å™¨
            max_items: æœ€å¤§æŠ“å–æ•°é‡

        Returns:
            å…ƒç´ æ•°æ®åˆ—è¡¨
        """
        items = []
        elems = self.page.query_selector_all(selector)

        print(f"æ‰¾åˆ° {len(elems)} ä¸ªå…ƒç´ ")

        for idx, elem in enumerate(elems[:max_items]):
            try:
                text = elem.inner_text()
                if text and len(text.strip()) > 0:
                    items.append({
                        "index": idx + 1,
                        "text": text.strip(),
                        "html": elem.inner_html()
                    })
            except Exception as e:
                continue

        return items

    def screenshot(self, path: str, full_page: bool = False):
        """
        æˆªå›¾

        Args:
            path: ä¿å­˜è·¯å¾„
            full_page: æ˜¯å¦å…¨é¡µæˆªå›¾
        """
        self.page.screenshot(path=path, full_page=full_page)
        print(f"ğŸ“¸ æˆªå›¾ä¿å­˜åˆ°: {path}")

    def pdf(self, path: str):
        """ç”Ÿæˆ PDF"""
        self.page.pdf(path=path)
        print(f"ğŸ“„ PDF ä¿å­˜åˆ°: {path}")

    def evaluate(self, script: str):
        """æ‰§è¡Œ JavaScript"""
        return self.page.evaluate(script)

    def get_url(self) -> str:
        """è·å–å½“å‰ URL"""
        return self.page.url

    def get_title(self) -> str:
        """è·å–é¡µé¢æ ‡é¢˜"""
        return self.page.title()

    def scroll_to_bottom(self, slow: bool = True, max_scrolls: int = 10):
        """
        æ»šåŠ¨é¡µé¢åˆ°åº•éƒ¨ï¼ˆç”¨äºåŠ è½½æ›´å¤šå†…å®¹ï¼‰

        Args:
            slow: æ˜¯å¦ç¼“æ…¢æ»šåŠ¨
            max_scrolls: æœ€å¤§æ»šåŠ¨æ¬¡æ•°
        """
        print(f"ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹...")

        if slow:
            for i in range(max_scrolls):
                self.page.evaluate("window.scrollBy(0, 800)")
                time.sleep(1)  # å¢åŠ ç­‰å¾…æ—¶é—´
                # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ°åº•éƒ¨
                scroll_height = self.page.evaluate("document.documentElement.scrollHeight")
                scroll_top = self.page.evaluate("document.documentElement.scrollTop")
                client_height = self.page.evaluate("document.documentElement.clientHeight")
                if scroll_top + client_height >= scroll_height - 100:
                    break
                print(f"   æ»šåŠ¨ä¸­... ({i+1}/{max_scrolls})")
        else:
            self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(3)

    def click_element(self, selector: str, timeout: int = 5000):
        """
        ç‚¹å‡»å…ƒç´ å¹¶ç­‰å¾…å¯¼èˆª

        Args:
            selector: å…ƒç´ é€‰æ‹©å™¨
            timeout: è¶…æ—¶æ—¶é—´
        """
        try:
            print(f"ğŸ–±ï¸  ç‚¹å‡»å…ƒç´ : {selector}")
            self.page.click(selector, timeout=timeout)
            time.sleep(2)
        except Exception as e:
            print(f"âš ï¸  ç‚¹å‡»å¤±è´¥: {e}")

    def scrape_reviews(self, review_selectors: List[Dict[str, str]], max_reviews: int = 50, scroll: bool = True) -> List[Dict[str, Any]]:
        """
        çˆ¬å–å•†å“è¯„ä»·

        Args:
            review_selectors: è¯„ä»·é€‰æ‹©å™¨é…ç½®åˆ—è¡¨
                [{"container": "é€‰æ‹©å™¨", "user": "ç”¨æˆ·é€‰æ‹©å™¨", "content": "å†…å®¹é€‰æ‹©å™¨", "rating": "è¯„åˆ†é€‰æ‹©å™¨", "date": "æ—¥æœŸé€‰æ‹©å™¨"}]
            max_reviews: æœ€å¤§è¯„ä»·æ•°é‡
            scroll: æ˜¯å¦æ»šåŠ¨åŠ è½½æ›´å¤šè¯„ä»·

        Returns:
            è¯„ä»·åˆ—è¡¨
        """
        reviews = []
        print(f"ğŸ’¬ å¼€å§‹çˆ¬å–è¯„ä»·...")

        # å¦‚æœéœ€è¦æ»šåŠ¨ï¼Œå…ˆæ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šè¯„ä»·
        if scroll:
            self.scroll_to_bottom(slow=True, max_scrolls=15)
            time.sleep(2)

        # å°è¯•å¤šç§é€‰æ‹©å™¨é…ç½®
        for config in review_selectors:
            try:
                container_selector = config.get("container", "")
                user_selector = config.get("user", "")
                content_selector = config.get("content", "")
                rating_selector = config.get("rating", "")
                date_selector = config.get("date", "")

                review_elems = self.page.query_selector_all(container_selector)
                print(f"ä½¿ç”¨é€‰æ‹©å™¨ '{container_selector}' æ‰¾åˆ° {len(review_elems)} æ¡è¯„ä»·")

                for idx, elem in enumerate(review_elems[:max_reviews]):
                    try:
                        review = {"index": idx + 1}

                        # æå–ç”¨æˆ·å
                        if user_selector:
                            user_elem = elem.query_selector(user_selector)
                            if user_elem:
                                review["user"] = user_elem.inner_text().strip()

                        # æå–è¯„ä»·å†…å®¹
                        if content_selector:
                            content_elem = elem.query_selector(content_selector)
                            if content_elem:
                                review["content"] = content_elem.inner_text().strip()

                        # æå–è¯„åˆ†
                        if rating_selector:
                            rating_elem = elem.query_selector(rating_selector)
                            if rating_elem:
                                review["rating"] = rating_elem.inner_text().strip()
                                # å°è¯•è·å–å±æ€§ä¸­çš„è¯„åˆ†
                                if not review["rating"]:
                                    review["rating"] = rating_elem.get_attribute("title") or ""

                        # æå–æ—¥æœŸ
                        if date_selector:
                            date_elem = elem.query_selector(date_selector)
                            if date_elem:
                                review["date"] = date_elem.inner_text().strip()

                        # å¦‚æœè‡³å°‘æœ‰å†…å®¹å°±æ·»åŠ 
                        if "content" in review and review["content"]:
                            reviews.append(review)

                    except Exception as e:
                        continue

                # å¦‚æœæ‰¾åˆ°äº†è¯„ä»·ï¼Œå°±ä¸å†å°è¯•å…¶ä»–é€‰æ‹©å™¨
                if len(reviews) > 0:
                    print(f"âœ“ æˆåŠŸæå– {len(reviews)} æ¡è¯„ä»·")
                    break

            except Exception as e:
                print(f"âš ï¸  é€‰æ‹©å™¨ '{config.get('container', '')}' å¤±è´¥: {e}")
                continue

        return reviews

    def scrape_all_elements(self, selector: str, max_items: int = 20) -> List[Dict[str, Any]]:
        """
        æŠ“å–æ‰€æœ‰åŒ¹é…çš„å…ƒç´ 

        Args:
            selector: å…ƒç´ é€‰æ‹©å™¨
            max_items: æœ€å¤§æŠ“å–æ•°é‡

        Returns:
            å…ƒç´ æ•°æ®åˆ—è¡¨
        """
        items = []
        elems = self.page.query_selector_all(selector)

        print(f"æ‰¾åˆ° {len(elems)} ä¸ªå…ƒç´ ")

        for idx, elem in enumerate(elems[:max_items]):
            try:
                text = elem.inner_text()
                if text and len(text.strip()) > 0:
                    items.append({
                        "index": idx + 1,
                        "text": text.strip(),
                        "html": elem.inner_html()
                    })
            except Exception as e:
                continue

        return items

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        print("ğŸ”š å…³é—­æµè§ˆå™¨...")
        if self.page:
            self.page.close()
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()
